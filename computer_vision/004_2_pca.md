# Principal Component Analysis

## Variance and Covariance
Both are measures of the “spread” of a set of points around their center of mass (mean)

- **Variance** measures of the deviation from the mean for points in one dimension e.g. heights
- **Covariance** measures of how much each of the dimensions vary from the mean with respect to each other.
    $$\text{Cov}(x, y) = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{n}$$
    - Notice how the formula represents the relation between both variables variations:
        - **each variation** from the mean $(x_i - \bar{x})$ or $(y_i - \bar{y})$
        - All these variations are averaged, then
            - If the covariance is positive, both dimensions increase or decrease together
            - If the covariance is negative, while one increases the other decreases
            - If the covariance is zero, the two dimensions are independent of each other  

- **Covariance matrix** represents the covariance between dimensions.
    - Diagonal is the variances of x, y, and z
    - cov(x,y) = cov(y,x)
    - N-dimensional data will result in NxN covariance matrix
- **Usefulness**: Covariance calculations are used to find relationships between dimensions in high dimensional data sets (usually greater than 3) where visualization is difficult.

## Principal Component Analysis (PCA)

- PCA is a technique that can be used to simplify a dataset
- PCA is a linear transformation that chooses a new coordinate system for the data set such that, greatest variance by any projection of the data set comes to lie on the first top axis (then called the principal components).
    - Your new coordinate system shows you how much the data varies in what direction.
- PCA can be used for reducing dimensionality by eliminating the last axis (no substantial principal
components).

**How it works?** By finding the eigenvalues and eigenvectors of the covariance matrix, we find that the eigenvectors with the largest eigenvalues correspond to the dimensions that have the strongest correlation in the dataset.

Process:
1. Take your original coordinates and data.
2. Calculate eigen-vectors to see where the largest direction of change is.
3. Then, you can take the more relevant top vectors, which capture more of the variance on the data.

TODO: Review the slides to check equations and how this algorithm works in a mathematical sense.
