# Temporal Data Notion of State Space Model
The following explanation tries to explain what to do when we don't consider iid in the data

- The observations can come in the form of time series, which mean that some data point actually are dependent from past data points.
    - We consider in this scenarios that the data is generated from the (often unobservable!) underlying process ('The nature') that evolves in time
- The goal is **to generalize beyond observations", and to do that we must somehow capture the "Nature" - i.e. the law describing how the underlying dynamics evolve over time.

- To start modelling this mathematical framework, we rely on the idea of "Information processing states" (IPS), which form an State Space Models.
    - IPSs are practically an abstractions that encapsulates all the possible contents of a specific situation.
        - e.g. state 1: all sequence with odd numbers of b's or state 2: all the sequences with even number of b's
    - These IPS are used in automata that defines how you from one state to other
- Sometimes, it is difficult to handle all the possible sequence of histories because they can even be infinite.
    - In those cases, we can use a small context (window, memory) and used that as observation. Then, we can make conclusion in a probabilistic way that given a certain context, we can predict the next possible state (or observation) in the sequence.
    - **state** is the general nature and **observation** is generated by the state.
    - However, this thing still has a problem. It is that, in some problems, we don't have enough data to model all the possible conditional probabilities. We can address that problem with memory dependent or dynamic context.
- Memory dependent (dynamic context), you only need 
    - a large context in some escenarios (e.g. complicated words),
    - in another, it is ok to work with small context (e.g. 'ing' probabily space the next one)
    - Example of method: Prediction suffix Trees
        - Universal Information Source (in Information theory)
        - Use in a lot of compression algorithms.

- A State Space model will always come with two equations
    1.  The first equation indicates how is your **underlying state evolving**, and can take different forms
        - automatic discrete
        - automatic continuous
        - automatic stochastic
        - input-based discrete
        - input-based continuous
        - input-based stochastic
    2. The second equation indicates how your observations are **created** from your underlying state space (nature)**, and can take different forms
        - automatic discrete
        - automatic stochastic
        - input-based discrete
        - input-based stochastic
    - Then you are going to have a set of observations and you need to determine
        1. your function h (a mapping from state to observations, or the stochastic prob variant)
        2. your function f a state transition function (a mapping from state to new state, or the stochastic prob variante)
            - NOTE: f can also change over time as f_t, which makes the problem a non-stationary problem.
            - It is practically to identify the nature f

# Hidden Markov Models

- Markov Model of order 1, when the probability of moving from one state to other only depends on the current state, not a history of states.
- We can use Markov Models to model situation when my nature is non-stationary, but it still organize in finite number of discrete regimes
    - these regimes change more slowly than the frequency of observations that you see
    - and you can describe how the regimes are changing to so call transitions probabilities.
- You have from one side
    - emition probabilities of each state (in case of the bags it would the proportion)
    - and transition probabilities
- But notice in the HMM setup, we are not able of totally sure say in which state you are by only looking to the observations.
    - we can establish emition probabilities of each regime and transition probabilities, but can not say with certainty in which state you are. You only can provide a probability.
- A general problem: if it's not easy to determine a state using a particular observation sequence, this is your problem the sum over all the possibilities of the rollout of the whole states.
## Questions

- How u make those conclusions about the context (or memory size)? For example, why do u say that the financial market indeed has a shallow memory?
    - How u know how to differentiate when you need a large or shot window?
- I don't understand the difference too well about the state and observation difference
    - For example, in the simple case of the string:
        - The states would these 1 and 2.
            - state 1 is composed of all those strings that have an even number of 'b's
            - state 2 is composed of all those strings that have an odd number of b's
            - Then, an observation would be only a few of those strings, right? Or what?
            - What would be an observation? An observation can also be only a small description of those strings as you mention a small window of the actual strings.???
- If we don't have access to the state $x_t$, how do you formulate those equations? Because as they are written, it seems like you need the state to predict the observation. It shouldn't be the other way around?
- This is the mathematical background to formulate reinforcement learning, right?

**HHM Questions**
- Non-stationarity is given by these blue arrow probabilities that change from one state to other (from one distrbution of balls to others). Is in that way the non-stationarity represented, right?
