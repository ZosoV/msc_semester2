{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 02: Smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Calculate the probability of the sentence i want chinese food. Give two probabilities,\n",
    "one using Fig. 3.2 and another using the add-1 smoothed table in Fig. 3.7. Assume\n",
    "the additional add-1 smoothed probabilities P (i| < s >) = 0.19 and P (< /s >\n",
    "|f ood) = 0.40.**\n",
    "\n",
    "**NOTE**: also consider the following probabilities for the first table\n",
    "P (i| < s >) = 0.25 and P (< /s > |food) = 0.68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00018961800000000004"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_zero_probs = 0.25 * 0.33 * 0.0065 * 0.52 * 0.68\n",
    "p_zero_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4067679999999995e-06"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_add_1_smoothed = 0.19 * 0.21 * 0.0029 * 0.052 * 0.4\n",
    "p_add_1_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Which of the two probabilities you computed in the previous exercise is higher,\n",
    "unsmoothed or smoothed? Explain why.**\n",
    "\n",
    "The probability using the first table (with zeros probs) is higer than the probability\n",
    "using add 1 smoothed table.\n",
    "\n",
    "It is because the add 1 smoothness process is shaving off a bit of the probability mass from \n",
    "some more frequent events and give it to the events with zero prob. Consequently, if we calculate\n",
    "the probability of the sentences using the probability of the bigrams in the second table.\n",
    "These bigrams' probabilities will be lower, and the whole sentence's probability will be lower as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. We are given the following corpus, modified from the example Dr Seuss corpus:**\n",
    "```\n",
    "<s> I am Sam </s>\n",
    "<s> Sam I am </s>\n",
    "<s> I am Sam </s>\n",
    "<s> I do not like green eggs and Sam </s>\n",
    "```\n",
    "**Using a bigram language model with add-one smoothing, what is P (Sam|am)? Include < s > and < /s > in your counts just like any other token.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, '<s>'),\n",
       "             (1, 'I'),\n",
       "             (2, 'am'),\n",
       "             (3, 'Sam'),\n",
       "             (4, '</s>'),\n",
       "             (5, 'do'),\n",
       "             (6, 'not'),\n",
       "             (7, 'like'),\n",
       "             (8, 'green'),\n",
       "             (9, 'eggs'),\n",
       "             (10, 'and')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "corpus = '''\n",
    "<s> I am Sam </s>\n",
    "<s> Sam I am </s>\n",
    "<s> I am Sam </s>\n",
    "<s> I do not like green eggs and Sam </s>\n",
    "'''\n",
    "\n",
    "corpus = re.findall(r'[A-Za-z0-9|(<s>)|(</s>)]+', corpus)\n",
    "vocabulary = Counter(corpus)\n",
    "vocabulary\n",
    "\n",
    "vocab2index = OrderedDict([ (key, i) for i, key in enumerate(vocabulary.keys())])\n",
    "vocab2index\n",
    "\n",
    "index2vocab = OrderedDict([ (i, key) for i, key in enumerate(vocabulary.keys())])\n",
    "index2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<s>', 'I'): 3,\n",
       "         ('I', 'am'): 3,\n",
       "         ('am', 'Sam'): 2,\n",
       "         ('Sam', '</s>'): 3,\n",
       "         ('</s>', '<s>'): 3,\n",
       "         ('<s>', 'Sam'): 1,\n",
       "         ('Sam', 'I'): 1,\n",
       "         ('am', '</s>'): 1,\n",
       "         ('I', 'do'): 1,\n",
       "         ('do', 'not'): 1,\n",
       "         ('not', 'like'): 1,\n",
       "         ('like', 'green'): 1,\n",
       "         ('green', 'eggs'): 1,\n",
       "         ('eggs', 'and'): 1,\n",
       "         ('and', 'Sam'): 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_consecutive_tuples(lst, n = 2):\n",
    "    tuples = []\n",
    "    for i in range(len(lst) - n + 1):\n",
    "        tuple_n = tuple(lst[i:i+n])\n",
    "        tuples.append(tuple_n)\n",
    "    tuples = Counter(tuples)\n",
    "    return tuples\n",
    "\n",
    "tuples_n_counters = find_consecutive_tuples(corpus)\n",
    "tuples_n_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.75       0.         0.25       0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.75       0.         0.         0.25\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.66666667 0.33333333 0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.25       0.         0.         0.75       0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.75       0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# only bigram\n",
    "\n",
    "def unsmoothed_bigram_probs(vocabulary,  vocab2index, tuples_n_counters):\n",
    "    bigram_matrix = np.zeros((len(vocabulary), len(vocabulary)))\n",
    "    bigram_matrix\n",
    "\n",
    "    for tuple_n, count in tuples_n_counters.items():\n",
    "        first_word, second_word = tuple_n\n",
    "\n",
    "        idx_1 = vocab2index[first_word]\n",
    "        idx_2 = vocab2index[second_word]\n",
    "\n",
    "        bigram_matrix[idx_1,idx_2] = count / vocabulary[first_word] \n",
    "\n",
    "    print(bigram_matrix)\n",
    "\n",
    "unsmoothed_bigram_probs(vocabulary,  vocab2index, tuples_n_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only bigram\n",
    "\n",
    "def add_1_smoothed_bigram_probs(vocabulary,  index2vocab, tuples_n_counters):\n",
    "    bigram_matrix = np.zeros((len(vocabulary), len(vocabulary)))\n",
    "    \n",
    "    for i in range(len(vocabulary)):\n",
    "        for j in range(len(vocabulary)):\n",
    "\n",
    "            first_word = index2vocab[i]\n",
    "            second_word = index2vocab[j]\n",
    "\n",
    "            if (first_word, second_word) in tuples_n_counters:\n",
    "                count = tuples_n_counters[(first_word, second_word)]\n",
    "            else:\n",
    "                count = 1\n",
    "\n",
    "            bigram_matrix[i,j] = (count + 1) / (vocabulary[first_word] + len(vocabulary) )\n",
    "\n",
    "    return bigram_matrix\n",
    "\n",
    "bigram_matrix = add_1_smoothed_bigram_probs(vocabulary,  index2vocab, tuples_n_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Sam|am) 0.21428571428571427\n"
     ]
    }
   ],
   "source": [
    "bigram = (\"am\",\"Sam\")\n",
    "index1 = vocab2index[bigram[0]]\n",
    "index2 = vocab2index[bigram[1]]\n",
    "\n",
    "print(f\"P({bigram[1]}|{bigram[0]})\", bigram_matrix[index1,index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From my hand calculation I got\n",
    "3/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Suppose we train a trigram language model with add-one smoothing on a given\n",
    "corpus. The corpus contains V word types. Express a formula for estimating\n",
    "P (w3|w1, w2), where w3 is a word which follows the bigram (w1,w2), in terms of\n",
    "various n-gram counts and V. Use the notation c(w1,w2,w3) to denote the number\n",
    "of times that trigram (w1,w2,w3) occurs in the corpus, and so on for bigrams and\n",
    "unigrams.**\n",
    "\n",
    "NOTE: In ipad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
